################################################################################
### AUTO-GPT - GENERAL SETTINGS
################################################################################

## EXECUTE_LOCAL_COMMANDS - Allow local command execution (Default: False)
## RESTRICT_TO_WORKSPACE - Restrict file operations to workspace ./auto_gpt_workspace (Default: True)
# EXECUTE_LOCAL_COMMANDS=False
# RESTRICT_TO_WORKSPACE=True

## USER_AGENT - Define the user-agent used by the requests library to browse website (string)
# USER_AGENT="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36"

## AI_SETTINGS_FILE - Specifies which AI Settings file to use (defaults to ai_settings.yaml)
# AI_SETTINGS_FILE=ai_settings.yaml

<<<<<<< Updated upstream
=======
## PROMPT_SETTINGS_FILE - Specifies which Prompt Settings file to use (defaults to prompt_settings.yaml)
# PROMPT_SETTINGS_FILE=prompt_settings.yaml

## AUTHORISE COMMAND KEY - Key to authorise commands
# AUTHORISE_COMMAND_KEY=y
## EXIT_KEY - Key to exit AUTO-GPT
# EXIT_KEY=n

## PLAIN_OUTPUT - Enabeling plain output will disable spinner (Default: False)
## Note: Spinner is used to indicate that Auto-GPT is working on something in the background
# PLAIN_OUTPUT=False

## DISABLED_COMMAND_CATEGORIES - The list of categories of commands that are disabled. Each of the below are an option:
## autogpt.commands.analyze_code
## autogpt.commands.audio_text
## autogpt.commands.execute_code
## autogpt.commands.file_operations
## autogpt.commands.git_operations
## autogpt.commands.google_search
## autogpt.commands.image_gen
## autogpt.commands.improve_code
## autogpt.commands.web_selenium
## autogpt.commands.write_tests
## autogpt.app
## autogpt.commands.task_statuses
## For example, to disable coding related features, uncomment the next line
# DISABLED_COMMAND_CATEGORIES=autogpt.commands.analyze_code,autogpt.commands.execute_code,autogpt.commands.git_operations,autogpt.commands.improve_code,autogpt.commands.write_tests

## DENY_COMMANDS - The list of commands that are not allowed to be executed by Auto-GPT (Default: None)
# the following are examples:
# DENY_COMMANDS=cd,nano,vim,vi,emacs,rm,sudo,top,ping,ssh,scp

## ALLOW_COMMANDS - ONLY those commands will be allowed to be executed by Auto-GPT
# the following are examples:
ALLOW_COMMANDS=ls,git,cat,grep,find,echo,ps,curl,wget


>>>>>>> Stashed changes
################################################################################
### LLM PROVIDER
################################################################################

### OPENAI
## OPENAI_API_KEY - OpenAI API Key (Example: my-openai-api-key)
## TEMPERATURE - Sets temperature in OpenAI (Default: 0)
## USE_AZURE - Use Azure OpenAI or not (Default: False)
OPENAI_API_KEY=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
# TEMPERATURE=0.01
# USE_AZURE=False
# OPENAI_ORGANIZATION=org-b3l38rNUlxObzZ5mW9rSB9TK

### AZURE
# moved to `azure.yaml.template`

################################################################################
### LLM MODELS
################################################################################

## SMART_LLM_MODEL - Smart language model (Default: gpt-4)
## FAST_LLM_MODEL - Fast language model (Default: gpt-3.5-turbo)
# SMART_LLM_MODEL=gpt-4
# FAST_LLM_MODEL=gpt-3.5-turbo

### LLM MODEL SETTINGS
## FAST_TOKEN_LIMIT - Fast token limit for OpenAI (Default: 4000)
## SMART_TOKEN_LIMIT - Smart token limit for OpenAI (Default: 8000)
## When using --gpt3only this needs to be set to 4000.
# FAST_TOKEN_LIMIT=4000
# SMART_TOKEN_LIMIT=8000

<<<<<<< Updated upstream
=======
### EMBEDDINGS
## EMBEDDING_MODEL       - Model to use for creating embeddings
# EMBEDDING_MODEL=text-embedding-ada-002

>>>>>>> Stashed changes
################################################################################
### MEMORY
################################################################################

### MEMORY_BACKEND - Memory backend type
## json_file - Default
## redis - Redis (if configured)
<<<<<<< Updated upstream
## milvus - Milvus (if configured)
=======
>>>>>>> Stashed changes
## MEMORY_INDEX - Name of index created in Memory backend (Default: auto-gpt)
# MEMORY_BACKEND=json_file
# MEMORY_INDEX=auto-gpt-memory

### REDIS
## REDIS_HOST - Redis host (Default: localhost, use "redis" for docker-compose)
## REDIS_PORT - Redis port (Default: 6379)
## REDIS_PASSWORD - Redis password (Default: "")
## WIPE_REDIS_ON_START - Wipes data / index on start (Default: True)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_PASSWORD=
# WIPE_REDIS_ON_START=True

<<<<<<< Updated upstream
### WEAVIATE
## MEMORY_BACKEND - Use 'weaviate' to use Weaviate vector storage
## WEAVIATE_HOST - Weaviate host IP
## WEAVIATE_PORT - Weaviate host port
## WEAVIATE_PROTOCOL - Weaviate host protocol (e.g. 'http')
## USE_WEAVIATE_EMBEDDED - Whether to use Embedded Weaviate
## WEAVIATE_EMBEDDED_PATH - File system path were to persist data when running Embedded Weaviate
## WEAVIATE_USERNAME - Weaviate username
## WEAVIATE_PASSWORD - Weaviate password
## WEAVIATE_API_KEY - Weaviate API key if using API-key-based authentication
# WEAVIATE_HOST="127.0.0.1"
# WEAVIATE_PORT=8080
# WEAVIATE_PROTOCOL="http"
# USE_WEAVIATE_EMBEDDED=False
# WEAVIATE_EMBEDDED_PATH="/home/me/.local/share/weaviate"
# WEAVIATE_USERNAME=
# WEAVIATE_PASSWORD=
# WEAVIATE_API_KEY=

### MILVUS
## MILVUS_ADDR - Milvus remote address (e.g. localhost:19530)
## MILVUS_COLLECTION - Milvus collection,
## change it if you want to start a new memory and retain the old memory.
# MILVUS_ADDR=your-milvus-cluster-host-port
# MILVUS_COLLECTION=autogpt

=======
>>>>>>> Stashed changes
################################################################################
### IMAGE GENERATION PROVIDER
################################################################################

### COMMON SETTINGS
## IMAGE_PROVIDER - Image provider - dalle, huggingface, or sdwebui
## IMAGE_SIZE - Image size (Example: 256)
## Image sizes for dalle: 256, 512, 1024
# IMAGE_PROVIDER=dalle
# IMAGE_SIZE=256

### HUGGINGFACE
## HUGGINGFACE_IMAGE_MODEL - Text-to-image model from Huggingface (Default: CompVis/stable-diffusion-v1-4)
## HUGGINGFACE_API_TOKEN - HuggingFace API token (Example: my-huggingface-api-token)
HUGGINGFACE_IMAGE_MODEL=CompVis/stable-diffusion-v1-4
HUGGINGFACE_API_TOKEN=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

### STABLE DIFFUSION WEBUI
## SD_WEBUI_AUTH - Stable diffusion webui username:password pair (Example: username:password)
## SD_WEBUI_URL - Stable diffusion webui API URL (Example: http://127.0.0.1:7860)
SD_WEBUI_AUTH=
SD_WEBUI_URL=http://127.0.0.1:7860

################################################################################
### AUDIO TO TEXT PROVIDER
################################################################################

### HUGGINGFACE
# HUGGINGFACE_AUDIO_TO_TEXT_MODEL=facebook/wav2vec2-base-960h

################################################################################
### GIT Provider for repository actions
################################################################################

### GITHUB
## GITHUB_API_KEY - Github API key / PAT (Example: github_pat_123)
## GITHUB_USERNAME - Github username
GITHUB_API_KEY=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
# GITHUB_USERNAME=yaboyshades

################################################################################
### WEB BROWSING
################################################################################

### BROWSER
## HEADLESS_BROWSER - Whether to run the browser in headless mode (default: True)
## USE_WEB_BROWSER - Sets the web-browser driver to use with selenium (default: chrome).
##   Note: set this to either 'chrome', 'firefox', or 'safari' depending on your current browser
# HEADLESS_BROWSER=True
# USE_WEB_BROWSER=edge
## BROWSE_CHUNK_MAX_LENGTH - When browsing website, define the length of chunks to summarize (in number of tokens, excluding the response. 75 % of FAST_TOKEN_LIMIT is usually wise )
# BROWSE_CHUNK_MAX_LENGTH=3000
## BROWSE_SPACY_LANGUAGE_MODEL is used to split sentences. Install additional languages via pip, and set the model name here. Example Chinese:  python -m spacy download zh_core_web_sm
# BROWSE_SPACY_LANGUAGE_MODEL=en_core_web_sm

### GOOGLE
## GOOGLE_API_KEY - Google API key (Example: my-google-api-key)
## CUSTOM_SEARCH_ENGINE_ID - Custom search engine ID (Example: my-custom-search-engine-id)
# GOOGLE_API_KEY=AIzaSyCz6ecsfJuetlNrP0DdRMFuMecXrjKQeLw
# CUSTOM_SEARCH_ENGINE_ID=https://cse.google.com/cse?cx=4433541fd19604c1f

################################################################################
### TTS PROVIDER
################################################################################

### MAC OS
## USE_MAC_OS_TTS - Use Mac OS TTS or not (Default: False)
# USE_MAC_OS_TTS=False

### STREAMELEMENTS
## USE_BRIAN_TTS - Use Brian TTS or not (Default: False)
# USE_BRIAN_TTS=False

### ELEVENLABS
## ELEVENLABS_API_KEY - Eleven Labs API key (Example: my-elevenlabs-api-key)
## ELEVENLABS_VOICE_1_ID - Eleven Labs voice 1 ID (Example: my-voice-id-1)
## ELEVENLABS_VOICE_2_ID - Eleven Labs voice 2 ID (Example: my-voice-id-2)
# ELEVENLABS_API_KEY=https://cse.google.com/cse?cx=4433541fd19604c1f
# ELEVENLABS_VOICE_1_ID=MYCOMPUTERVOICE
# ELEVENLABS_VOICE_2_ID=ATHENA THE ROBOT

################################################################################
### TWITTER API
################################################################################

# TW_CONSUMER_KEY=
# TW_CONSUMER_SECRET=
# TW_ACCESS_TOKEN=
# TW_ACCESS_TOKEN_SECRET=
